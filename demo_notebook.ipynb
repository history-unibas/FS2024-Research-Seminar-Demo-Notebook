{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einleitung\n",
    "Dieses Jupyter Notebook demonstriert, wie aufbereitete Daten des Historischen Grundbuchs der Stadt Basel durchsucht werden können.\n",
    "\n",
    "Bemerkung: Je nach Suche, Suchbegriff und Suchzeitraum kann die Suche einige Zeit dauern.\n",
    "\n",
    "TODO\n",
    "- Weitere Informationen zum HGB?\n",
    "- Weitere Informationen zum zur Verfügung gestellten Datensatz. Welche Daten sind vorhanden, Aussage über Genauigkeit, Datenschema,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importiere Packages\n",
    "Importiere für dieses Skript notwendige Funktionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipyleaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import Transformer\n",
    "from ipyleaflet import Map, WMSLayer, Circle, Popup\n",
    "import ipywidgets as widgets\n",
    "from thefuzz import fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entpacke Datengrundlage\n",
    "Entpacke für die Suche verwendete Datengrundlage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasource for the search.\n",
    "FILEPATH_DATASOURCE = './hgb_corpus_24_07_26_inline_full_updated.zip'\n",
    "\n",
    "# Unzip the file.\n",
    "with zipfile.ZipFile(FILEPATH_DATASOURCE, 'r') as myzip:\n",
    "    myzip.extractall('.')\n",
    "\n",
    "# Update the filepath.\n",
    "FILEPATH_DATASOURCE = os.path.splitext(FILEPATH_DATASOURCE)[0] + '.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freitextsuche\n",
    "Beispiel: Suche nach dem Begriff \"Wysung\" in Paragraphen von Dokumenten im Zeitraum 1550 – 1600."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiere Suchparameter\n",
    "Festlegen der gewünschten Parameter für die Suche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set search word.\n",
    "SEARCH_KEYWORD = 'wysung'\n",
    "\n",
    "# Define search period.\n",
    "YEAR_MIN = 1550\n",
    "YEAR_MAX = 1600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suche ausführen\n",
    "Durchführung der Freitextsuche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load xml file.\n",
    "context = ET.iterparse(FILEPATH_DATASOURCE, events=('start', 'end'))\n",
    "\n",
    "# Create an empty dataframe to store the search results.\n",
    "results = pd.DataFrame(\n",
    "    columns=['id', 'house', 'coord_x', 'coord_y',\n",
    "             'pages', 'year', 'text', 'imagelinks'\n",
    "             ]\n",
    "    )\n",
    "\n",
    "# Iterate over each element.\n",
    "collection_element = None\n",
    "for event, elem in context:\n",
    "\n",
    "    # The start event is triggered when the parser encounters the opening tag of an element.\n",
    "    if event == 'start' and elem.tag == 'Collection':\n",
    "            \n",
    "        # Store current collection element.\n",
    "        collection_element = elem\n",
    "    \n",
    "    # The end event is triggered when the parser encounters the closing tag of an element.\n",
    "    elif event == 'end' and elem.tag == 'Document':\n",
    "            \n",
    "        # Get the header element.\n",
    "        header = elem.find('Header')\n",
    "        \n",
    "        # Determine the year of the document.\n",
    "        year = int(header.get('year'))\n",
    "\n",
    "        # Skip the document if not in desired search period.\n",
    "        if year < YEAR_MIN or year > YEAR_MAX:\n",
    "            continue\n",
    "\n",
    "        # Get the text attribute.\n",
    "        text = header.get('text')\n",
    "\n",
    "        # Search for keyword in text.\n",
    "        if SEARCH_KEYWORD in text:\n",
    "        \n",
    "            # Store selected elements in dataframe.\n",
    "            results.loc[len(results)] = [\n",
    "                collection_element.attrib['id'],\n",
    "                collection_element.attrib['house'],\n",
    "                collection_element.attrib['coord_x'],\n",
    "                collection_element.attrib['coord_y'],\n",
    "                header.get('pages'),\n",
    "                year,\n",
    "                text,\n",
    "                header.get('imagelinks')\n",
    "                ]\n",
    "\n",
    "# Print the number of search results.\n",
    "print(f'The keyword \"{SEARCH_KEYWORD}\" was found in {results.shape[0]} documents '\n",
    "      f'in the period {YEAR_MIN} - {YEAR_MAX}.'\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ergebnisse in Tabelle darstellen\n",
    "Die Suchergebnisse werden in einer Tabelle dargestellt. Der Suchbegriff wird im Text vorgehoben und das zugehörige Digitalisat zur Verfügung gestellt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the table of results for the display. \n",
    "filtered_results = results[['id', 'house', 'pages', 'year', 'text', 'imagelinks']].copy()\n",
    "\n",
    "# Define the integration of the images in the table.\n",
    "def make_clickable_images(val):\n",
    "    urls = val.split(\" | \")\n",
    "    img_tags = [f'<a href=\"{url}\" target=\"_blank\"><img src=\"{url}\" width=\"100\" /></a>' for url in urls]\n",
    "    return \" \".join(img_tags)\n",
    "\n",
    "filtered_results['imagelinks'] = filtered_results['imagelinks'].apply(make_clickable_images)\n",
    "\n",
    "# Highlight the search word.\n",
    "def highlight_keyword(keyword, val):\n",
    "    val = val.replace(\"\\n\", \"<br>\")\n",
    "    if keyword in val:\n",
    "        return val.replace(f'{keyword}', f'<span style=\"color: red;\">{keyword}</span>')\n",
    "    return val\n",
    "\n",
    "filtered_results['text'] = filtered_results['text'].apply(\n",
    "    lambda x: highlight_keyword(SEARCH_KEYWORD, x)\n",
    "    )\n",
    "\n",
    "# Render the dataframe as HTML on show the table.\n",
    "html = filtered_results.to_html(escape=False, max_rows=10)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogramm der Resultate über die Zeit\n",
    "Die Verteilung der Suchresultate über den Suchzeitraum wird in einem Histogramm visualisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the appearance of the histogram.\n",
    "plt.figure(figsize=(10, 6))\n",
    "n, bins, patches = plt.hist(\n",
    "    results['year'],\n",
    "    bins=range(min(results['year']), max(results['year']), 1),\n",
    "    edgecolor='black'\n",
    "    )\n",
    "plt.title('Histogram')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.gca().set_axisbelow(True)\n",
    "plt.yticks(np.arange(0, np.max(n) + 1, 1))\n",
    "\n",
    "# Display the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisiere Ergebnisse im Raum\n",
    "Die Suchresultate werden als Punkte auf dem \"Loeffel\"-Plan dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the coordinates of the search results.\n",
    "def transform_coords(x, y):\n",
    "    transformer = Transformer.from_crs(2056, 4326)\n",
    "    return transformer.transform(x, y)\n",
    "results['lat'], results['lon'] = zip(*results.apply(\n",
    "    lambda row: transform_coords(row['coord_x'], row['coord_y']), axis=1\n",
    "    ))\n",
    "\n",
    "# Define the basemap.\n",
    "wms = WMSLayer(\n",
    "    url='https://wms.geo.bs.ch/',\n",
    "    layers='HP_Uebersichtsplaene_Basel_Situationsplan1862',\n",
    "    attribution='Geodaten Kanton Basel-Stadt'\n",
    ")\n",
    "m = Map(basemap=wms, center=(47.557, 7.595), zoom=14)\n",
    "\n",
    "# Add the search results to the map.\n",
    "for index, row in results.iterrows():\n",
    "    \n",
    "    # Create Circle.\n",
    "    circle = Circle(location=(row['lat'], row['lon']),\n",
    "                    radius=3,\n",
    "                    color='blue',\n",
    "                    fill_color='blue')\n",
    "    \n",
    "    # Add pop-up to display attributes of the circle.\n",
    "    popup_content = f\"\"\"ID: {row['id']}<br>\n",
    "    House: {row['house']}<br>\n",
    "    Pages: {row['pages']}<br>\n",
    "    Year: {row['year']}\"\"\"\n",
    "    popup = Popup(location=(row['lat'], row['lon']), child=widgets.HTML(popup_content), close_button=True)\n",
    "    circle.popup = popup\n",
    "\n",
    "    # Add the circle to the map.\n",
    "    m.add_layer(circle)\n",
    "\n",
    "#  Display the map.\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suchresultate exportieren\n",
    "Exportiere Suchergebnisse als Exceltabelle in Arbeitsverzeichnis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel('search_results.xlsx', index=False)\n",
    "print('Search results were exported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy-Suche\n",
    "\n",
    "Die \"Fuzzy\"-Suche ist eine fehlertolerante Suche.\n",
    "\n",
    "Beispiel: Suche nach dem Begriff \"wisung\" (Standardschreibweise) in Paragraphen von Dokumenten im Zeitraum 1550 – 1600.\n",
    "\n",
    "Mit dem \"Verhältnis-Schwellenwert\" wird definiert, wie ähnlich Suchresultate zum Suchbegriff sein sollen. Je kleiner dieser Wert, je mehr Treffer werden generiert.\n",
    "\n",
    "TODO\n",
    "- Standardschreibweise definieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiere Suchparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set search word.\n",
    "SEARCH_KEYWORD = 'wisung'\n",
    "\n",
    "# Define search period.\n",
    "YEAR_MIN = 1550\n",
    "YEAR_MAX = 1600\n",
    "\n",
    "# Ratio threshold between 0 and 100.\n",
    "RATIO_THRESHOLD = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suche ausführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import process\n",
    "\n",
    "# Load xml file.\n",
    "context = ET.iterparse(FILEPATH_DATASOURCE, events=('start', 'end'))\n",
    "\n",
    "# Create an empty dataframe to store the search results.\n",
    "results = pd.DataFrame(\n",
    "    columns=['id', 'house', 'coord_x', 'coord_y',\n",
    "             'pages', 'year', 'text', 'imagelinks',\n",
    "             'ratio', 'found_term']\n",
    "    )\n",
    "\n",
    "# Iterate over each element.\n",
    "collection_element = None\n",
    "for event, elem in context:\n",
    "    if event == 'start' and elem.tag == 'Collection':\n",
    "            \n",
    "        # Store current collection element.\n",
    "        collection_element = elem\n",
    "    \n",
    "    elif event == 'end' and elem.tag == 'Document':\n",
    "            \n",
    "        # Get the header element.\n",
    "        header = elem.find('Header')\n",
    "        \n",
    "        # Determine the year of the document.\n",
    "        year = int(header.get('year'))\n",
    "\n",
    "        # Skip the document if not in desired search period.\n",
    "        if year < YEAR_MIN or year > YEAR_MAX:\n",
    "            continue\n",
    "\n",
    "        # Get the text attribute.\n",
    "        text = header.get('text')\n",
    "\n",
    "        # Perform a fuzzy search.\n",
    "        #ratio = fuzz.partial_token_sort_ratio(SEARCH_KEYWORD, text)\n",
    "        keyword_ratio = process.extractOne(SEARCH_KEYWORD, text.split(), score_cutoff=RATIO_THRESHOLD, scorer=fuzz.ratio)\n",
    "\n",
    "        # Search for keyword in text.\n",
    "        if keyword_ratio is not None:\n",
    "\n",
    "            keyword, ratio = keyword_ratio\n",
    "\n",
    "            # Store selected elements in dataframe.\n",
    "            results.loc[len(results)] = [\n",
    "                collection_element.attrib['id'],\n",
    "                collection_element.attrib['house'],\n",
    "                collection_element.attrib['coord_x'],\n",
    "                collection_element.attrib['coord_y'],\n",
    "                header.get('pages'),\n",
    "                year,\n",
    "                text,\n",
    "                header.get('imagelinks'),\n",
    "                ratio,\n",
    "                keyword\n",
    "                ]\n",
    "\n",
    "# Print the number of search results.\n",
    "print(f'The fuzzy search with the search term \"{SEARCH_KEYWORD}\" '\n",
    "      f'found {results.shape[0]} of documents in the period between '\n",
    "      f'{YEAR_MIN} and {YEAR_MAX} with a ratio of {RATIO_THRESHOLD} or more.'\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the table of results for the display. \n",
    "filtered_results = results[['id', 'house', 'pages', 'year', 'text', 'imagelinks', 'found_term']].copy()\n",
    "\n",
    "# Define the integration of the images in the table.\n",
    "def make_clickable_images(val):\n",
    "    urls = val.split(\" | \")\n",
    "    img_tags = [f'<a href=\"{url}\" target=\"_blank\"><img src=\"{url}\" width=\"100\" /></a>' for url in urls]\n",
    "    return \" \".join(img_tags)\n",
    "\n",
    "filtered_results['imagelinks'] = filtered_results['imagelinks'].apply(make_clickable_images)\n",
    "\n",
    "# Highlight the search word.\n",
    "def highlight_keyword(keyword, val):\n",
    "    keyword = val['found_term']\n",
    "    val = val['text']\n",
    "    val = val.replace('\\n', '<br>')\n",
    "    if keyword in val:\n",
    "        return val.replace(f'{keyword}', f'<span style=\"color: red;\">{keyword}</span>')\n",
    "    return val\n",
    "\n",
    "filtered_results['text'] = filtered_results.apply(\n",
    "    lambda x: highlight_keyword(SEARCH_KEYWORD, x),\n",
    "    axis=1\n",
    "    )\n",
    "\n",
    "# Render the dataframe as HTML on show the table.\n",
    "html = filtered_results.to_html(escape=False, max_rows=10)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suche nach Entität\n",
    "Annotationssuche nach einer Entität.\n",
    "\n",
    "\n",
    "Beispiel: Suche nach dem Begriff \"Fischer\" in Paragraphen von Dokumenten im Zeitraum 1550 – 1600.\n",
    "\n",
    "\n",
    "TODO\n",
    "- Definieren, was eine Entität ist.\n",
    "- Parameter MENTION_SUBTYPE definieren.\n",
    "- Mögliche Werte für MENTION_SUBTYPE definieren.\n",
    "- Ev. Normalisierung definieren\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suchparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set search word.\n",
    "SEARCH_KEYWORD = 'Fischer'\n",
    "\n",
    "# Define the mention subtype.\n",
    "MENTION_SUBTYPE = 'occ'\n",
    "\n",
    "# Define search period.\n",
    "YEAR_MIN = 1550\n",
    "YEAR_MAX = 1600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suche ausführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load xml file.\n",
    "context = ET.iterparse(FILEPATH_DATASOURCE, events=('start', 'end'))\n",
    "\n",
    "# Create an empty dataframe to store the search results.\n",
    "results = pd.DataFrame(\n",
    "    columns=['id', 'house', 'coord_x', 'coord_y',\n",
    "             'pages', 'year', 'text', 'imagelinks',\n",
    "             'head', 'confidence'\n",
    "             ]\n",
    "    )\n",
    "\n",
    "# Iterate over each element.\n",
    "collection_element = None\n",
    "for event, elem in context:\n",
    "    if event == 'start' and elem.tag == 'Collection':\n",
    "            \n",
    "        # Store current collection element.\n",
    "        collection_element = elem\n",
    "    \n",
    "    elif event == 'end' and elem.tag == 'Document':\n",
    "            \n",
    "        # Get the header element.\n",
    "        header = elem.find('Header')\n",
    "        \n",
    "        # Determine the year of the document.\n",
    "        year = int(header.get('year'))\n",
    "\n",
    "        # Skip the document if not in desired search period.\n",
    "        if year < YEAR_MIN or year > YEAR_MAX:\n",
    "            continue\n",
    "        \n",
    "        # Iterate over all attributes of the document.\n",
    "        for attribute in elem.findall(f'.//Attribute[@mention_subtype=\"{MENTION_SUBTYPE}\"]'):\n",
    "            # Get the header text.\n",
    "            head = attribute.find('.//Head')\n",
    "            head_text = head.text\n",
    "\n",
    "            # Search for keyword in text.\n",
    "            if head_text and SEARCH_KEYWORD in head_text:\n",
    "            \n",
    "                # Store selected elements in dataframe.\n",
    "                results.loc[len(results)] = [\n",
    "                    collection_element.attrib['id'],\n",
    "                    collection_element.attrib['house'],\n",
    "                    collection_element.attrib['coord_x'],\n",
    "                    collection_element.attrib['coord_y'],\n",
    "                    header.get('pages'),\n",
    "                    year,\n",
    "                    header.get('text'),\n",
    "                    header.get('imagelinks'),\n",
    "                    head_text,\n",
    "                    attribute.attrib.get('confidence')\n",
    "                    ]\n",
    "\n",
    "# Print the number of search results.\n",
    "print(f'The keyword \"{SEARCH_KEYWORD}\" was found in {results.shape[0]} entities of '\n",
    "      f'entity mention subtype \"{MENTION_SUBTYPE}\" in documents from the period {YEAR_MIN} to {YEAR_MAX}.'\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the table of results for the display. \n",
    "filtered_results = results[['id', 'house', 'pages', 'year', 'text', 'imagelinks']].copy()\n",
    "\n",
    "# Define the integration of the images in the table.\n",
    "def make_clickable_images(val):\n",
    "    urls = val.split(\" | \")\n",
    "    img_tags = [f'<a href=\"{url}\" target=\"_blank\"><img src=\"{url}\" width=\"100\" /></a>' for url in urls]\n",
    "    return \" \".join(img_tags)\n",
    "\n",
    "filtered_results['imagelinks'] = filtered_results['imagelinks'].apply(make_clickable_images)\n",
    "\n",
    "# Highlight the search word.\n",
    "def highlight_keyword(keyword, val):\n",
    "    val = val.replace(\"\\n\", \"<br>\")\n",
    "    if keyword in val:\n",
    "        return val.replace(f'{keyword}', f'<span style=\"color: red;\">{keyword}</span>')\n",
    "    return val\n",
    "\n",
    "filtered_results['text'] = filtered_results['text'].apply(\n",
    "    lambda x: highlight_keyword(SEARCH_KEYWORD, x)\n",
    "    )\n",
    "\n",
    "# Render the dataframe as HTML on show the table.\n",
    "html = filtered_results.to_html(escape=False, max_rows=10)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suche nach Event\n",
    "Annotationssuche nach einem Event.\n",
    "\n",
    "Beispiel: Suche nach dem Begriff \"gefrönt\" in Paragraphen von Dokumenten im Zeitraum 1550 – 1600.\n",
    "\n",
    "\n",
    "TODO\n",
    "- Definieren, was ein Event ist.\n",
    "- Parameter EVENT_TYPE definieren.\n",
    "- Mögliche Werte für EVENT_TYPE definieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suchparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set search word.\n",
    "SEARCH_KEYWORD = 'gefrönt'\n",
    "\n",
    "# Define the event type.\n",
    "EVENT_TYPE = 'seizure'\n",
    "\n",
    "# Define search period.\n",
    "YEAR_MIN = 1550\n",
    "YEAR_MAX = 1600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suche ausführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load xml file.\n",
    "context = ET.iterparse(FILEPATH_DATASOURCE, events=('start', 'end'))\n",
    "\n",
    "# Create an empty dataframe to store the search results.\n",
    "results = pd.DataFrame(\n",
    "    columns=['id', 'house', 'coord_x', 'coord_y',\n",
    "             'pages', 'year', 'text', 'imagelinks',\n",
    "             'trigger_text', 'confidence'\n",
    "             ]\n",
    "    )\n",
    "\n",
    "# Iterate over each element.\n",
    "collection_element = None\n",
    "for event, elem in context:\n",
    "    if event == 'start' and elem.tag == 'Collection':\n",
    "            \n",
    "        # Store current collection element.\n",
    "        collection_element = elem\n",
    "    \n",
    "    elif event == 'end' and elem.tag == 'Document':\n",
    "            \n",
    "        # Get the header element.\n",
    "        header = elem.find('Header')\n",
    "        \n",
    "        # Determine the year of the document.\n",
    "        year = int(header.get('year'))\n",
    "\n",
    "        # Skip the document if not in desired search period.\n",
    "        if year < YEAR_MIN or year > YEAR_MAX:\n",
    "            continue\n",
    "        \n",
    "        # Iterate over all events of the document.\n",
    "        for doc_event in elem.findall('.//Event'):\n",
    "            if doc_event.attrib.get('type') == EVENT_TYPE:\n",
    "\n",
    "                # Get the trigger text attribute.\n",
    "                trigger = doc_event.find('.//Trigger')\n",
    "                trigger_text = trigger.attrib.get('text')\n",
    "                \n",
    "                # Search for keyword in text.\n",
    "                if SEARCH_KEYWORD in trigger_text:\n",
    "                \n",
    "                    # Store selected elements in dataframe.\n",
    "                    results.loc[len(results)] = [\n",
    "                        collection_element.attrib['id'],\n",
    "                        collection_element.attrib['house'],\n",
    "                        collection_element.attrib['coord_x'],\n",
    "                        collection_element.attrib['coord_y'],\n",
    "                        header.get('pages'),\n",
    "                        year,\n",
    "                        header.get('text'),\n",
    "                        header.get('imagelinks'),\n",
    "                        trigger_text,\n",
    "                        trigger.attrib.get('confidence')\n",
    "                        ]\n",
    "\n",
    "# Print the number of search results.\n",
    "print(f'The keyword \"{SEARCH_KEYWORD}\" was found in {results.shape[0]} events of '\n",
    "      f'event type \"{EVENT_TYPE}\" in documents from the period {YEAR_MIN} to {YEAR_MAX}.'\n",
    "      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
